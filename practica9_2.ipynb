{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practica9_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hesolar/TrabajoDistribuidos2020solar-escudero/blob/master/practica9_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6phqqXPIv6hp"
      },
      "source": [
        "# Práctica 9 Parte 2: Análisis de sentimientos\n",
        "\n",
        "El análisis de sentimientos es un problema de procesado de lenguaje natural donde se pretende conocer la intención de un texto. En esta práctica vamos a ver cómo predecir el sentimiento, positivo o negativo, de una valoracion de una película.\n",
        "\n",
        "En esta ocasión vamos a utilizar la librería de deep learning [Keras](https://keras.io/).\n",
        "\n",
        "\n",
        "En esta práctica es importante que actives el uso de GPU. Para ello ve al menú Edit -> Notebook settings y en la opción Hardware accelerator selecciona la opción de GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuxiF_2TwdXJ"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "El dataset usado en esta sesión es el dataset [IMDB](http://ai.stanford.edu/~amaas/data/sentiment/). Dicho dataset contiene 25000 valoraciones (positivas y negativas) para entrenar, y 25000 valoraciones  para testear. El objetivo es ser capaz de determinar si una valoración de una película es positiva o negativa. \n",
        "\n",
        "Keras proporciona acceso directo al dataset IMDB en un formato listo para ser usado por las redes neuronales, lo que evita tener que descargarlo y procesarlo. La función ``imdb.load_data()`` permite cargar el dataset donde las palabras han sido reemplazadas por enteros que indican la popularidad (número de apariciones)  de una palabra en el dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKUmkF-Kv5nK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd999ce-6095-479b-de02-951bf751907d"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.datasets import imdb\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "(X_train,y_train), (X_test,y_test) = imdb.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUgMh_RNxqxN"
      },
      "source": [
        "A continuación mostramos la forma del dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-6xEME5xhSL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee72e2c-5725-4d50-aeaa-d34697935981"
      },
      "source": [
        "print(\"Datos entrenamiento: \")\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(\"Datos test: \")\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datos entrenamiento: \n",
            "(25000,)\n",
            "(25000,)\n",
            "Datos test: \n",
            "(25000,)\n",
            "(25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3tU1rzR02ml"
      },
      "source": [
        "Podemos también mostrar que aspecto tienen los elementos de nuestro dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp1zZjX30XvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c966bb27-dcef-48e7-916c-06e15dfa337b"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 22665,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 21631,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 19193,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 10311,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 31050,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 12118,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vny1jGOW07rt"
      },
      "source": [
        "A partir de la instrucción anterior podemos ver que los elementos de nuestro dataset se representan mediante una lista de enteros, donde cada entero está asociado a una palabra. Para restaurar el mensaje original podemos ejecutar el siguiente comando."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U-wuB5V1HlN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "982cecc2-5ee9-4069-efb8-7becc1d65030"
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "' '.join([reverse_word_index.get(i - 3, '?') for i in X_train[0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2xguDlUx4HE"
      },
      "source": [
        "Podemos también mostrar el número de clases (veremos que nos devuelve dos clases, el 0 representa una valoración negativa y el 1 una valoración positiva)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2Is1hLMx3lH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "471849ba-92a7-481d-f5aa-7b9c1583ce2d"
      },
      "source": [
        "print(\"Clases: \")\n",
        "print(np.unique(y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clases: \n",
            "[0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXAyv1tRyA0p"
      },
      "source": [
        "También podemos ver el número total de palabras del dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-wdh746x0ys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fce8a6ba-d405-432e-c90d-4f75408ed3f3"
      },
      "source": [
        "print(\"Número de palabras: \")\n",
        "print(len(np.unique(np.hstack(X_train))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Número de palabras: \n",
            "88585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI_wbtThyLeE"
      },
      "source": [
        "Finalmente, podemos ver la longitud media de las valoraciones. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDpgxcCKyHZy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "f5e6d696-208c-49f0-a3c3-40be8ae46fb6"
      },
      "source": [
        "print(\"Longitud media: \")\n",
        "result = [len(x) for x in X_train]\n",
        "print(\"Media %.2f palabras (%f)\" % (np.mean(result),np.std(result)))\n",
        "plt.subplot(121)\n",
        "plt.boxplot(result)\n",
        "plt.subplot(122)\n",
        "plt.hist(result)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longitud media: \n",
            "Media 238.71 palabras (176.493674)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sporAx6Fy8U2"
      },
      "source": [
        "##### Ejercicio\n",
        "A partir de los diagramas anteriores, ¿qué puedes decir del tamaño de las valoraciones? ¿Cuál sería el tamaño de la valoración más larga (para esta pregunta puedes ejecutar alguna instrucción adicional)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQCPtm-9ZNtS"
      },
      "source": [
        "La mayoría de valoraciones están concentradas aproximadamente entre los intervalos 0-500 , la media está próxima a 200."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEOgsZZNS-6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a14837-4ecb-4535-c4e9-ba10d21a0b7a"
      },
      "source": [
        "result = [len(x) for x in X_train]\n",
        "print(\"Máximo de palabras (%f)\" % (max(result)))\n",
        "print(\"Media %.2f palabras (%f)\" % (np.mean(result),np.std(result)))\n",
        "print(\"Min de palabras (%f)\" % (min(result)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Máximo de palabras (2494.000000)\n",
            "Media 238.71 palabras (176.493674)\n",
            "Min de palabras (11.000000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK8fKDD8zU1N"
      },
      "source": [
        "## Word embeddings\n",
        "\n",
        "Como ya hemos visto, uno de los grandes avances más recientes en el área del procesamiento de lenguaje natural son los *word embeddings*. Los *word embeddings* son una técnica donde las palabras se codifican como vectores de reales en un espacio de dimensión alta, donde las similaridad entre palabras se traduce en cercanía de los vectores. Esto s muy útil ya que al trabajar con redes neuronales se requiere una conversión de las palabras a números. \n",
        "\n",
        "Por el momento no vamos a usar ningún word embedding de los vistos con anterioridad, sino que vamos aprenderlos directamente a partir de nuestros datos. Keras proporciona una manera sencilla de convertir representaciones de palabras mediante enteros positios a un word embedding mediante una capa de ``Embedding``. Esta capa toma argumentos que definen la asociación de palabras a vectores. Estos argumentos incluyen el número máximo de palabras esperadas, también conocido como el tamaño del vocabulario. Esta capa también permite especificar la dimensionalidad de la representación.\n",
        "\n",
        "Queremos usar una representación para nuestro dataset. Digamos que estamos interesados en las 5000 palabras más usadas del dataset. Por lo tanto, nuestro vocabulario tendrá 5000 elementos. También podemos elegir usar un vector de dimensión 32 para representar cada una de las palabras. Finalmente, podemos fijar que la longitud máxima de las valoraciones sea de 500 palabras, truncando aquellas que son más largas y añadiendo ceros a las que son más cortas. Vamos a obtener de nuevo nuestro dataset teniendo esto en cuenta. También vamos a definir un conjunto de validación usando el 20% del conjunto de entrenamiento. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_NDC7Nb18NR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99ec5f74-b3ef-46f3-fe24-987bf8beeafd"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "(X_train,y_train), (X_test,y_test) = imdb.load_data(num_words=5000)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SK9-Tl_hb_8"
      },
      "source": [
        "Podemos ahora truncar o completar cada una de las valoraciones para que contenga 500 palabras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSzzZrpMhbvc"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_val = sequence.pad_sequences(X_val, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnzqo7W1hsjS"
      },
      "source": [
        "## Modelo Red Neuronal Simple\n",
        "\n",
        "Vamos a construir varios modelos para nuestro dataset. Comenzaremos con una red neuronal multicapa con una única capa oculta. La innovación será la capa de word embedding que muestra cómo se pueden conseguir buenos resultados con un modelo tan simple. \n",
        "\n",
        "Comenzamos importando las funciones necesarias e inicializando una semilla para obtener resultados consistentes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRgSo0KxhVpk"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "seed = 15\n",
        "np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4WK-RLKiOc1"
      },
      "source": [
        "A continuación creamos nuestro modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWSEjE-FiMIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc49df2-45dd-4a9d-dd9b-d3746dbc175c"
      },
      "source": [
        "top_words = 5000\n",
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(top_words,32,input_length=max_words))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(250,activation='relu'))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model\n",
        "\n",
        "model1 = create_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 250)               4000250   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 4,160,501\n",
            "Trainable params: 4,160,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3lFAC4Qim6l"
      },
      "source": [
        "Vamos ahora a entrenar el modelo y a mostrar su curva de entrenamiento y validación. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka-LkfnTikox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815628c1-a89c-42c3-9f77-4c40b6768b3c"
      },
      "source": [
        "history = model1.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=10,batch_size=128,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 17s 103ms/step - loss: 0.6197 - accuracy: 0.6243 - val_loss: 0.3383 - val_accuracy: 0.8508\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 16s 101ms/step - loss: 0.1783 - accuracy: 0.9338 - val_loss: 0.3083 - val_accuracy: 0.8750\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 16s 101ms/step - loss: 0.0524 - accuracy: 0.9884 - val_loss: 0.4021 - val_accuracy: 0.8652\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 16s 102ms/step - loss: 0.0110 - accuracy: 0.9992 - val_loss: 0.4725 - val_accuracy: 0.8680\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 16s 102ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5352 - val_accuracy: 0.8672\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 16s 101ms/step - loss: 8.8725e-04 - accuracy: 1.0000 - val_loss: 0.5619 - val_accuracy: 0.8672\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 16s 100ms/step - loss: 4.7260e-04 - accuracy: 1.0000 - val_loss: 0.5873 - val_accuracy: 0.8678\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 16s 101ms/step - loss: 3.1935e-04 - accuracy: 1.0000 - val_loss: 0.6055 - val_accuracy: 0.8690\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 16s 100ms/step - loss: 2.3185e-04 - accuracy: 1.0000 - val_loss: 0.6242 - val_accuracy: 0.8690\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 16s 100ms/step - loss: 1.6593e-04 - accuracy: 1.0000 - val_loss: 0.6405 - val_accuracy: 0.8690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oai2aUhzj1ru",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "292c65fb-5438-4020-d756-f14e9f559b44"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, 'bo')\n",
        "plt.plot(epochs, val_acc, 'b')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze17EMFCkr8J"
      },
      "source": [
        "##### Ejercicio\n",
        "A partir de las gráficas anteriores ¿qué problema tiene nuestro modelo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DszxMXUAZsK"
      },
      "source": [
        "Que no se ajusta a los datos de entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWpWs2Nckwzl"
      },
      "source": [
        "Respuesta: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIZkZl59k47Z"
      },
      "source": [
        "Para evitar el problema anterior, vamos a entrenar de nuevo nuestra red, pero sólo 2 épocas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6FNEw_nkwRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71830864-0841-48a6-ffc6-9f10a22ae6d3"
      },
      "source": [
        "model2 = create_model()\n",
        "model2.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=2,batch_size=128,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 16000)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 250)               4000250   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 4,160,501\n",
            "Trainable params: 4,160,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/2\n",
            "157/157 [==============================] - 16s 102ms/step - loss: 0.6475 - accuracy: 0.5823 - val_loss: 0.3040 - val_accuracy: 0.8714\n",
            "Epoch 2/2\n",
            "157/157 [==============================] - 16s 100ms/step - loss: 0.1930 - accuracy: 0.9279 - val_loss: 0.3033 - val_accuracy: 0.8778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f28489ba610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6GSdAl0lR3d"
      },
      "source": [
        "Por último, evaluamos nuestro modelo en el conjunto de test. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK6mqa7ilC-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6ed7f7-1ae2-4165-c32f-59f88c969a28"
      },
      "source": [
        "scores = model2.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 86.88%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC52vpEllnzr"
      },
      "source": [
        "Podemos también evaluar el modelo que tenía el problema y podemos ver que la accuracy es peor que la que hemos obtenido con el otro modelo, a pesar de haberlo entrenado por menos tiempo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq1mZ62ilcyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2664aba-85e4-422b-bf94-dab0de8bd771"
      },
      "source": [
        "scores = model1.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 86.48%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjnMFte6l3KI"
      },
      "source": [
        "## Red neuronal convolucional de una dimensión\n",
        "\n",
        "Las redes neuronales convolucionales fueron creadas para tener en cuenta la estructura espacial de los datos en imágenes siendo robustas a cambios en la posición y orientación de los objetos. Este mismo principio se puede aplicar a secuencias como son las secuencias 1-dimensionales de palabras de una valoración de película.  Vamos a utilizar dicha propiedad en nuestro problema. \n",
        "\n",
        "Comenzamos cargando las librerías necesarias para trabajar con redes convolucionales 1-dimensionales. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZOstGNRl0tt"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Convolution1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlWLECjrmu7T"
      },
      "source": [
        "Definimos el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQrHI4dBmswa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c0668c0-ceb1-4992-e38f-45baed836fbc"
      },
      "source": [
        "def create_cnn_model():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(top_words,32,input_length=max_words))\n",
        "  model.add(Convolution1D(filters=32,kernel_size=3,padding='same',activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(250,activation='relu'))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model\n",
        "\n",
        "model3 = create_cnn_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 500, 32)           3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 250, 32)           0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 8000)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 250)               2000250   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 2,163,605\n",
            "Trainable params: 2,163,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6afTi6sNnPNy"
      },
      "source": [
        "Entrenamos este nuevo modelo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRzY8kF4nLym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb01589e-24fe-474b-863e-79ecf993b59b"
      },
      "source": [
        "model3.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=2,batch_size=128,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "157/157 [==============================] - 18s 112ms/step - loss: 0.6384 - accuracy: 0.5884 - val_loss: 0.2823 - val_accuracy: 0.8906\n",
            "Epoch 2/2\n",
            "157/157 [==============================] - 17s 110ms/step - loss: 0.2273 - accuracy: 0.9102 - val_loss: 0.2640 - val_accuracy: 0.8926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2847323350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHSZVP6_nWYF"
      },
      "source": [
        "Y evaluamos su precisión. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwzB0dVqnUXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d4753f7-e0a2-473f-caac-3e892952f039"
      },
      "source": [
        "scores = model3.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 88.32%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsbGqqqyndQ2"
      },
      "source": [
        "Como podemos ver, este modelo mejora los resultados obtenidos con el modelo anterior. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mDQSJRQnrQs"
      },
      "source": [
        "## LSTM\n",
        "\n",
        "Vamos a crear ahora una pequeña red LSTM. Como en casos anteriores comenzamos cargando las librerías necesarias. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aWkJRNRnbCu"
      },
      "source": [
        "from keras.layers import LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR1BM2Z2n2vx"
      },
      "source": [
        "Definimos el modelo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrX9oAPKn1XD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdddc690-1979-4f3a-dc8c-ac5d04597362"
      },
      "source": [
        "def create_lstm_model():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(top_words,32,input_length=max_words))\n",
        "  model.add(LSTM(100))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model\n",
        "\n",
        "model4 = create_lstm_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rSULKl_oOQG"
      },
      "source": [
        "Entrenamos el modelo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfXNhtt7oIAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f3458d-46c9-4fc7-d052-bb6a6b425ef3"
      },
      "source": [
        "model4.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=2,batch_size=128,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "157/157 [==============================] - 160s 1s/step - loss: 0.6531 - accuracy: 0.5935 - val_loss: 0.4141 - val_accuracy: 0.8170\n",
            "Epoch 2/2\n",
            "157/157 [==============================] - 157s 1s/step - loss: 0.3209 - accuracy: 0.8669 - val_loss: 0.3222 - val_accuracy: 0.8672\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2842f9cd10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ5frttYobKh"
      },
      "source": [
        "Y por último lo evaluamos contra el conjunto de test. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTLDWgMgoac3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb7892e-ac37-4e71-8d44-da9f9f1fa308"
      },
      "source": [
        "scores = model4.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 86.74%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8bqux5Xppmv"
      },
      "source": [
        "## LSTM con Dropout\n",
        "\n",
        "Uno de los problemas que tienen todas las redes que hemos definido hasta ahora es que tienden a sobreajustarse muy rápido. Para evitar dicho problema se puede utilizar la técnica de Dropout. \n",
        "\n",
        "Para ello definimos el siguiente modelo. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTen2yrTH2-7"
      },
      "source": [
        "from keras.layers import Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGsBXaOqohAA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b99dc97-442c-410d-9e17-2479ff644d37"
      },
      "source": [
        "def create_lstm_dropout_model():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(top_words,32,input_length=max_words))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(LSTM(100,dropout=0.2,recurrent_dropout=0.2))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model\n",
        "\n",
        "model5 = create_lstm_dropout_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 500, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUkSHypcqWSA"
      },
      "source": [
        "##### Ejercicio\n",
        "\n",
        "¿Por cuántas épocas puedes entrenar el nuevo modelo hasta que aparece el sobreajuste?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO9pv_Z3xINM"
      },
      "source": [
        "1 épocas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5A8Z6yKqNgz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "c80af95d-0deb-4bcb-fc6d-3803f5665fc4"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, 'bo')\n",
        "plt.plot(epochs, val_acc, 'b')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me8f6oPeq19p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "7a11b7de-b8fc-44b0-be41-7c59dd939c21"
      },
      "source": [
        "history = model5.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=10,batch_size=128,verbose=1)\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, 'bo')\n",
        "plt.plot(epochs, val_acc, 'b')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "  9/157 [>.............................] - ETA: 3:46 - loss: 0.6473 - accuracy: 0.7240"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-ffb6fcb02216>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlEqq67oxBrE"
      },
      "source": [
        "La he parado porque consume demasiado tiempos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQIuOOWXqxby"
      },
      "source": [
        "##### Ejercicio\n",
        "¿Qué accuracy consigues obtener con este nuevo modelo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy1smq3RJq3Q"
      },
      "source": [
        "0.88"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtNaqjrGq99k"
      },
      "source": [
        "## Predicciones propias\n",
        "\n",
        "Una vez construido nuestro modelo nos interesa probarlo con nuestras propias valoraciones. Para ello debemos convertir la frase a un formato que pueda alimentar a la red como se muestra a continuación. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDDVBruxrNa9"
      },
      "source": [
        "review = \"i generally love this type of movie however this time i found myself wanting to kick the screen since i can't do that i will just complain about it this was absolutely awful\"\n",
        "review = review.split(\" \")\n",
        "review = [word_index[w] for w in review]\n",
        "review = sequence.pad_sequences([review], maxlen=max_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhooNGoUsHvN"
      },
      "source": [
        "Y hacer la predicción con uno de nuestros modelos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E2_-XncrVHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97432d73-06f0-441c-d1d5-6d4fa2d6cff0"
      },
      "source": [
        "a=model4.predict(review)\n",
        "if a<=0.5:\n",
        "  print('negative review')\n",
        "if a>0.5:\n",
        "   print('positive review')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative review\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzXx3K-_tJcM"
      },
      "source": [
        "## Ejercicio obligatorio\n",
        "\n",
        "El problema que hemos visto es un problema de clasificación binaria, existe otro dataset, [Reuters](https://keras.io/api/datasets/reuters/), para la clasificación multiclase (dicho dataset está disponible en [Keras](https://keras.io/datasets/#reuters-newswire-topics-classification)). El ejercicio consite en entrenar un modelo (utilizando las mismas ideas presentadas en este notebook) para dicho problema. Ten en cuenta que con dicho dataset no podrás utilizar como función de pérdida ``binary_crossentropy`` (preparada para problemas binarios) sino que deberás usar la función de pérdida ``categorical_crossentropy``. Añade a continuación todas las celdas que necesites. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F1tUNMuyC-Y",
        "outputId": "a22f53cf-c8ad-4932-b755-2177fe56f320"
      },
      "source": [
        "#descargo librerias\n",
        "!pip install -q keras   \n",
        "import keras\n",
        "#preparo el dataset , tomo 1500 palabras para hacerlo rápido\n",
        "from keras.datasets import reuters\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(\n",
        "    path=\"reuters.npz\",\n",
        "    num_words=1500,\n",
        "    skip_top=0,\n",
        "    maxlen=None,\n",
        "    test_split=0.2,\n",
        "    seed=113,\n",
        "    start_char=1,\n",
        "    oov_char=2,\n",
        "    index_from=3\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHdui170y09C"
      },
      "source": [
        "Los datos son un conjunto de enteros que representan palabras\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwJUHYwwy-Hl",
        "outputId": "09fb8473-77c9-4c19-dc63-d4cfc1774e94"
      },
      "source": [
        "train_data[5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 4,\n",
              " 37,\n",
              " 38,\n",
              " 309,\n",
              " 213,\n",
              " 349,\n",
              " 2,\n",
              " 48,\n",
              " 193,\n",
              " 229,\n",
              " 463,\n",
              " 28,\n",
              " 156,\n",
              " 635,\n",
              " 11,\n",
              " 82,\n",
              " 14,\n",
              " 156,\n",
              " 635,\n",
              " 11,\n",
              " 82,\n",
              " 54,\n",
              " 139,\n",
              " 16,\n",
              " 349,\n",
              " 105,\n",
              " 462,\n",
              " 311,\n",
              " 28,\n",
              " 296,\n",
              " 147,\n",
              " 11,\n",
              " 82,\n",
              " 14,\n",
              " 296,\n",
              " 147,\n",
              " 11,\n",
              " 54,\n",
              " 139,\n",
              " 342,\n",
              " 48,\n",
              " 193,\n",
              " 2,\n",
              " 361,\n",
              " 122,\n",
              " 23,\n",
              " 1332,\n",
              " 28,\n",
              " 318,\n",
              " 942,\n",
              " 11,\n",
              " 82,\n",
              " 14,\n",
              " 318,\n",
              " 942,\n",
              " 11,\n",
              " 82,\n",
              " 54,\n",
              " 139,\n",
              " 122,\n",
              " 7,\n",
              " 105,\n",
              " 462,\n",
              " 23,\n",
              " 349,\n",
              " 28,\n",
              " 296,\n",
              " 767,\n",
              " 11,\n",
              " 82,\n",
              " 14,\n",
              " 296,\n",
              " 767,\n",
              " 11,\n",
              " 54,\n",
              " 139,\n",
              " 342,\n",
              " 229,\n",
              " 162,\n",
              " 7,\n",
              " 48,\n",
              " 193,\n",
              " 55,\n",
              " 408,\n",
              " 28,\n",
              " 258,\n",
              " 557,\n",
              " 11,\n",
              " 82,\n",
              " 14,\n",
              " 196,\n",
              " 557,\n",
              " 11,\n",
              " 82,\n",
              " 54,\n",
              " 139,\n",
              " 162,\n",
              " 7,\n",
              " 105,\n",
              " 462,\n",
              " 55,\n",
              " 349,\n",
              " 28,\n",
              " 191,\n",
              " 968,\n",
              " 11,\n",
              " 82,\n",
              " 14,\n",
              " 191,\n",
              " 785,\n",
              " 11,\n",
              " 54,\n",
              " 139,\n",
              " 17,\n",
              " 12]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "rvqmA7zyzaLh",
        "outputId": "f47d6042-0447-4acf-f6d8-0e023a0b8ca6"
      },
      "source": [
        "#Aquí se puede apreciar como obtener ls palabras desde los enteros\n",
        "word_index = reuters.get_word_index()\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])\n",
        "decoded_newswire"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'? ? ? said as a result of its december acquisition of ? co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and ? operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1DfszjX0BM0"
      },
      "source": [
        "import numpy as np\n",
        "#obtenemos las posiciones de las palabras\n",
        "def vectorize_sequences(sequences, dimension=1500):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "# Training data\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# Test data\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOZp4bxE0UGa"
      },
      "source": [
        "#mismo proceso para los datos de test\n",
        "def to_one_hot(labels, dimension=46):\n",
        "    results = np.zeros((len(labels), dimension))\n",
        "    for i, label in enumerate(labels):\n",
        "        results[i, label] = 1.\n",
        "    return results\n",
        "one_hot_train_labels = to_one_hot(train_labels)\n",
        "# Vectorized test labels\n",
        "one_hot_test_labels = to_one_hot(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d6sQB_a0eGD"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GnuX8HX0nha"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "#utilizamos un modelo simple de red\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(1500,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTGeKRTd1Jd0",
        "outputId": "63b7f6e1-30ee-444a-9357-15ad69e0b4a4"
      },
      "source": [
        "#Vamos a validar los datos contra el modelo\n",
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 2.5867 - accuracy: 0.4543 - val_loss: 1.3552 - val_accuracy: 0.7010\n",
            "Epoch 2/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1.2300 - accuracy: 0.7326 - val_loss: 1.1328 - val_accuracy: 0.7430\n",
            "Epoch 3/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.9495 - accuracy: 0.7894 - val_loss: 0.9956 - val_accuracy: 0.7700\n",
            "Epoch 4/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.7422 - accuracy: 0.8287 - val_loss: 0.9086 - val_accuracy: 0.7980\n",
            "Epoch 5/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.6159 - accuracy: 0.8613 - val_loss: 0.8700 - val_accuracy: 0.7950\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.5095 - accuracy: 0.8884 - val_loss: 0.8889 - val_accuracy: 0.7890\n",
            "Epoch 7/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.9057 - val_loss: 0.8490 - val_accuracy: 0.8070\n",
            "Epoch 8/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.3515 - accuracy: 0.9204 - val_loss: 0.8686 - val_accuracy: 0.8100\n",
            "Epoch 9/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.3115 - accuracy: 0.9274 - val_loss: 0.9054 - val_accuracy: 0.8040\n",
            "Epoch 10/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.2541 - accuracy: 0.9416 - val_loss: 0.9627 - val_accuracy: 0.7840\n",
            "Epoch 11/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.2245 - accuracy: 0.9467 - val_loss: 0.9374 - val_accuracy: 0.8170\n",
            "Epoch 12/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.2140 - accuracy: 0.9454 - val_loss: 0.9611 - val_accuracy: 0.8100\n",
            "Epoch 13/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.1778 - accuracy: 0.9510 - val_loss: 1.0144 - val_accuracy: 0.8000\n",
            "Epoch 14/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.1703 - accuracy: 0.9570 - val_loss: 1.0424 - val_accuracy: 0.8010\n",
            "Epoch 15/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.1706 - accuracy: 0.9500 - val_loss: 1.0673 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.1534 - accuracy: 0.9551 - val_loss: 1.0097 - val_accuracy: 0.8070\n",
            "Epoch 17/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.1345 - accuracy: 0.9612 - val_loss: 1.0779 - val_accuracy: 0.8000\n",
            "Epoch 18/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.1230 - accuracy: 0.9646 - val_loss: 1.1012 - val_accuracy: 0.7990\n",
            "Epoch 19/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.1224 - accuracy: 0.9620 - val_loss: 1.1041 - val_accuracy: 0.7920\n",
            "Epoch 20/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.1277 - accuracy: 0.9605 - val_loss: 1.1378 - val_accuracy: 0.7980\n",
            "Epoch 21/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.1226 - accuracy: 0.9596 - val_loss: 1.1344 - val_accuracy: 0.7990\n",
            "Epoch 22/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.1120 - accuracy: 0.9625 - val_loss: 1.1423 - val_accuracy: 0.7990\n",
            "Epoch 23/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.1106 - accuracy: 0.9619 - val_loss: 1.2192 - val_accuracy: 0.7870\n",
            "Epoch 24/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.1019 - accuracy: 0.9651 - val_loss: 1.2065 - val_accuracy: 0.7990\n",
            "Epoch 25/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0994 - accuracy: 0.9629 - val_loss: 1.2156 - val_accuracy: 0.7860\n",
            "Epoch 26/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.1117 - accuracy: 0.9588 - val_loss: 1.2376 - val_accuracy: 0.7910\n",
            "Epoch 27/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.1061 - accuracy: 0.9606 - val_loss: 1.1894 - val_accuracy: 0.7970\n",
            "Epoch 28/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.1134 - accuracy: 0.9608 - val_loss: 1.2014 - val_accuracy: 0.7960\n",
            "Epoch 29/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0966 - accuracy: 0.9643 - val_loss: 1.2781 - val_accuracy: 0.7870\n",
            "Epoch 30/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.1001 - accuracy: 0.9603 - val_loss: 1.2356 - val_accuracy: 0.7960\n",
            "Epoch 31/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0943 - accuracy: 0.9656 - val_loss: 1.3137 - val_accuracy: 0.7850\n",
            "Epoch 32/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0945 - accuracy: 0.9632 - val_loss: 1.2280 - val_accuracy: 0.7960\n",
            "Epoch 33/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0881 - accuracy: 0.9662 - val_loss: 1.2764 - val_accuracy: 0.7910\n",
            "Epoch 34/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0874 - accuracy: 0.9649 - val_loss: 1.2978 - val_accuracy: 0.7940\n",
            "Epoch 35/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0903 - accuracy: 0.9625 - val_loss: 1.2598 - val_accuracy: 0.7880\n",
            "Epoch 36/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0894 - accuracy: 0.9638 - val_loss: 1.2704 - val_accuracy: 0.7960\n",
            "Epoch 37/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0918 - accuracy: 0.9657 - val_loss: 1.3228 - val_accuracy: 0.7900\n",
            "Epoch 38/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0967 - accuracy: 0.9587 - val_loss: 1.3193 - val_accuracy: 0.7900\n",
            "Epoch 39/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0851 - accuracy: 0.9661 - val_loss: 1.3800 - val_accuracy: 0.7860\n",
            "Epoch 40/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0832 - accuracy: 0.9631 - val_loss: 1.3474 - val_accuracy: 0.7820\n",
            "Epoch 41/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0889 - accuracy: 0.9606 - val_loss: 1.3350 - val_accuracy: 0.7940\n",
            "Epoch 42/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0846 - accuracy: 0.9620 - val_loss: 1.3260 - val_accuracy: 0.7880\n",
            "Epoch 43/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0842 - accuracy: 0.9630 - val_loss: 1.4382 - val_accuracy: 0.7920\n",
            "Epoch 44/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.9603 - val_loss: 1.3649 - val_accuracy: 0.7850\n",
            "Epoch 45/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9659 - val_loss: 1.3302 - val_accuracy: 0.7850\n",
            "Epoch 46/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0823 - accuracy: 0.9628 - val_loss: 1.4112 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0839 - accuracy: 0.9626 - val_loss: 1.3685 - val_accuracy: 0.7910\n",
            "Epoch 48/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0802 - accuracy: 0.9627 - val_loss: 1.3638 - val_accuracy: 0.7890\n",
            "Epoch 49/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0768 - accuracy: 0.9635 - val_loss: 1.4512 - val_accuracy: 0.7840\n",
            "Epoch 50/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.0889 - accuracy: 0.9577 - val_loss: 1.3832 - val_accuracy: 0.7870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "YZv7ylkw1YTA",
        "outputId": "bdec2257-d9a5-4f58-a024-3e8b0194e42e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw_fxpmQy9Uz"
      },
      "source": [
        "Generamos predicciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQvOBFpk1wvK"
      },
      "source": [
        "predictions = model.predict(x_test)\n",
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyeSgNQY2CkW"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(1500,)))\n",
        "model.add(layers.Dense(4, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5ffTMBi2QNj"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zLN6ILq2R4D",
        "outputId": "e5d27a6b-3fbe-466e-b65f-a7011cc8ff40"
      },
      "source": [
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=50,\n",
        "          batch_size=128,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 3.4364 - accuracy: 0.0692 - val_loss: 2.3966 - val_accuracy: 0.6100\n",
            "Epoch 2/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 2.1129 - accuracy: 0.5992 - val_loss: 1.6472 - val_accuracy: 0.6130\n",
            "Epoch 3/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.5036 - accuracy: 0.6345 - val_loss: 1.4775 - val_accuracy: 0.6260\n",
            "Epoch 4/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.3816 - accuracy: 0.6376 - val_loss: 1.4249 - val_accuracy: 0.6500\n",
            "Epoch 5/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.2167 - accuracy: 0.7090 - val_loss: 1.3571 - val_accuracy: 0.6990\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.1375 - accuracy: 0.7309 - val_loss: 1.3170 - val_accuracy: 0.7100\n",
            "Epoch 7/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1.0511 - accuracy: 0.7465 - val_loss: 1.3070 - val_accuracy: 0.7080\n",
            "Epoch 8/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 1.0188 - accuracy: 0.7564 - val_loss: 1.2754 - val_accuracy: 0.7110\n",
            "Epoch 9/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 1.0067 - accuracy: 0.7520 - val_loss: 1.2680 - val_accuracy: 0.7140\n",
            "Epoch 10/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.9552 - accuracy: 0.7622 - val_loss: 1.2802 - val_accuracy: 0.7120\n",
            "Epoch 11/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.9175 - accuracy: 0.7724 - val_loss: 1.2696 - val_accuracy: 0.7070\n",
            "Epoch 12/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.8989 - accuracy: 0.7718 - val_loss: 1.2871 - val_accuracy: 0.7100\n",
            "Epoch 13/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.8628 - accuracy: 0.7786 - val_loss: 1.2764 - val_accuracy: 0.7070\n",
            "Epoch 14/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.8213 - accuracy: 0.7884 - val_loss: 1.3130 - val_accuracy: 0.7060\n",
            "Epoch 15/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.7924 - accuracy: 0.7938 - val_loss: 1.2891 - val_accuracy: 0.7090\n",
            "Epoch 16/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.7723 - accuracy: 0.7990 - val_loss: 1.3229 - val_accuracy: 0.7120\n",
            "Epoch 17/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.7563 - accuracy: 0.7988 - val_loss: 1.3103 - val_accuracy: 0.7170\n",
            "Epoch 18/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.7566 - accuracy: 0.8074 - val_loss: 1.3461 - val_accuracy: 0.7050\n",
            "Epoch 19/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.7007 - accuracy: 0.8161 - val_loss: 1.3461 - val_accuracy: 0.7030\n",
            "Epoch 20/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.6802 - accuracy: 0.8191 - val_loss: 1.3706 - val_accuracy: 0.7050\n",
            "Epoch 21/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.6558 - accuracy: 0.8231 - val_loss: 1.3738 - val_accuracy: 0.7160\n",
            "Epoch 22/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.6597 - accuracy: 0.8234 - val_loss: 1.4041 - val_accuracy: 0.7080\n",
            "Epoch 23/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.6422 - accuracy: 0.8305 - val_loss: 1.4414 - val_accuracy: 0.6990\n",
            "Epoch 24/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.6374 - accuracy: 0.8314 - val_loss: 1.4452 - val_accuracy: 0.7020\n",
            "Epoch 25/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.6173 - accuracy: 0.8328 - val_loss: 1.4524 - val_accuracy: 0.7070\n",
            "Epoch 26/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.6062 - accuracy: 0.8396 - val_loss: 1.4651 - val_accuracy: 0.7130\n",
            "Epoch 27/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.5727 - accuracy: 0.8499 - val_loss: 1.4911 - val_accuracy: 0.7030\n",
            "Epoch 28/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.6161 - accuracy: 0.8390 - val_loss: 1.5089 - val_accuracy: 0.7110\n",
            "Epoch 29/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.5495 - accuracy: 0.8527 - val_loss: 1.5541 - val_accuracy: 0.7030\n",
            "Epoch 30/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.5441 - accuracy: 0.8572 - val_loss: 1.5626 - val_accuracy: 0.7030\n",
            "Epoch 31/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.5351 - accuracy: 0.8542 - val_loss: 1.6000 - val_accuracy: 0.7030\n",
            "Epoch 32/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.5264 - accuracy: 0.8581 - val_loss: 1.6167 - val_accuracy: 0.7060\n",
            "Epoch 33/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.5109 - accuracy: 0.8628 - val_loss: 1.6522 - val_accuracy: 0.7060\n",
            "Epoch 34/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.4969 - accuracy: 0.8657 - val_loss: 1.6354 - val_accuracy: 0.7050\n",
            "Epoch 35/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.5099 - accuracy: 0.8622 - val_loss: 1.6973 - val_accuracy: 0.7060\n",
            "Epoch 36/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.8715 - val_loss: 1.7304 - val_accuracy: 0.7090\n",
            "Epoch 37/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.8685 - val_loss: 1.7219 - val_accuracy: 0.6990\n",
            "Epoch 38/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.8768 - val_loss: 1.7931 - val_accuracy: 0.7080\n",
            "Epoch 39/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.4578 - accuracy: 0.8765 - val_loss: 1.8101 - val_accuracy: 0.6980\n",
            "Epoch 40/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.8741 - val_loss: 1.8083 - val_accuracy: 0.7040\n",
            "Epoch 41/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8828 - val_loss: 1.8344 - val_accuracy: 0.7030\n",
            "Epoch 42/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.8792 - val_loss: 1.9084 - val_accuracy: 0.7080\n",
            "Epoch 43/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8831 - val_loss: 1.9304 - val_accuracy: 0.7000\n",
            "Epoch 44/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.8787 - val_loss: 1.9365 - val_accuracy: 0.7040\n",
            "Epoch 45/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8843 - val_loss: 1.9400 - val_accuracy: 0.7030\n",
            "Epoch 46/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8819 - val_loss: 2.0250 - val_accuracy: 0.6980\n",
            "Epoch 47/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8872 - val_loss: 2.0571 - val_accuracy: 0.7040\n",
            "Epoch 48/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.3613 - accuracy: 0.9003 - val_loss: 2.0718 - val_accuracy: 0.7020\n",
            "Epoch 49/50\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.3580 - accuracy: 0.8990 - val_loss: 2.0997 - val_accuracy: 0.7020\n",
            "Epoch 50/50\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8977 - val_loss: 2.1648 - val_accuracy: 0.7040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f284906d5d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oX2GUJZI2ZlS",
        "outputId": "e7d11f88-a3e6-480e-cc51-ec1fc9696889"
      },
      "source": [
        "results = model.evaluate(x_test, one_hot_test_labels)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 1ms/step - loss: 2.3783 - accuracy: 0.6643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3783419132232666, 0.6642920970916748]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbqRWAE7Nlli"
      },
      "source": [
        "## Ejercicio opcional \n",
        "\n",
        "A lo largo de la práctica los embeddings se han aprendido al entrenar la propia red. El ejercicio opcional consiste en utilizar embeddings preentrenados y utilizarlos para construir distintos modelos (ten en cuenta que deberás cambiar la estructura de las redes). Para esto puedes seguir el siguiente [tutorial de Keras](https://keras.io/examples/nlp/pretrained_word_embeddings/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTPppnccJSEw"
      },
      "source": [
        "**Esta Opción falla, está corregida más abajo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sek-f09Q5iaO"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import pathlib\n",
        "from tensorflow import keras\n",
        "os.mkdir('keras')\n",
        "\n",
        "os.mkdir('keras/datasets')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvrZj009NlH3"
      },
      "source": [
        "\n",
        "data_path = keras.utils.get_file(\n",
        "    \"news20.tar.gz\",\n",
        "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n",
        "    untar=True,\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeIbLw7V28AO",
        "outputId": "5221f734-b91b-4658-b8ce-fe6727e8fa08"
      },
      "source": [
        "\n",
        "\n",
        "data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n",
        "dirnames = os.listdir(data_dir)\n",
        "print(\"Number of directories:\", len(dirnames))\n",
        "print(\"Directory names:\", dirnames)\n",
        "\n",
        "fnames = os.listdir(data_dir / \"comp.graphics\")\n",
        "print(\"Number of files in comp.graphics:\", len(fnames))\n",
        "print(\"Some example filenames:\", fnames[:5])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of directories: 20\n",
            "Directory names: ['rec.motorcycles', 'talk.politics.misc', 'soc.religion.christian', 'talk.religion.misc', 'sci.space', 'alt.atheism', 'comp.graphics', 'sci.crypt', 'rec.sport.hockey', 'sci.med', 'talk.politics.mideast', 'comp.os.ms-windows.misc', 'sci.electronics', 'comp.sys.ibm.pc.hardware', 'comp.windows.x', 'rec.autos', 'comp.sys.mac.hardware', 'misc.forsale', 'talk.politics.guns', 'rec.sport.baseball']\n",
            "Number of files in comp.graphics: 1000\n",
            "Some example filenames: ['38774', '39045', '38623', '37944', '38917']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp_3kS7f3BRa",
        "outputId": "0a67fd6e-28bb-4d07-8b3e-8647fe94105c"
      },
      "source": [
        "print(open(data_dir / \"comp.graphics\" / \"38987\").read())\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Newsgroups: comp.graphics\n",
            "Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!howland.reston.ans.net!agate!dog.ee.lbl.gov!network.ucsd.edu!usc!rpi!nason110.its.rpi.edu!mabusj\n",
            "From: mabusj@nason110.its.rpi.edu (Jasen M. Mabus)\n",
            "Subject: Looking for Brain in CAD\n",
            "Message-ID: <c285m+p@rpi.edu>\n",
            "Nntp-Posting-Host: nason110.its.rpi.edu\n",
            "Reply-To: mabusj@rpi.edu\n",
            "Organization: Rensselaer Polytechnic Institute, Troy, NY.\n",
            "Date: Thu, 29 Apr 1993 23:27:20 GMT\n",
            "Lines: 7\n",
            "\n",
            "Jasen Mabus\n",
            "RPI student\n",
            "\n",
            "\tI am looking for a hman brain in any CAD (.dxf,.cad,.iges,.cgm,etc.) or picture (.gif,.jpg,.ras,etc.) format for an animation demonstration. If any has or knows of a location please reply by e-mail to mabusj@rpi.edu.\n",
            "\n",
            "Thank you in advance,\n",
            "Jasen Mabus  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o44Ye-E3Hq7",
        "outputId": "e2411967-12ad-45eb-fa84-91c34aa2c5f3"
      },
      "source": [
        "samples = []\n",
        "labels = []\n",
        "class_names = []\n",
        "class_index = 0\n",
        "for dirname in sorted(os.listdir(data_dir)):\n",
        "    class_names.append(dirname)\n",
        "    dirpath = data_dir / dirname\n",
        "    fnames = os.listdir(dirpath)\n",
        "    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n",
        "    for fname in fnames:\n",
        "        fpath = dirpath / fname\n",
        "        f = open(fpath, encoding=\"latin-1\")\n",
        "        content = f.read()\n",
        "        lines = content.split(\"\\n\")\n",
        "        lines = lines[10:]\n",
        "        content = \"\\n\".join(lines)\n",
        "        samples.append(content)\n",
        "        labels.append(class_index)\n",
        "    class_index += 1\n",
        "\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"Number of samples:\", len(samples))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing alt.atheism, 1000 files found\n",
            "Processing comp.graphics, 1000 files found\n",
            "Processing comp.os.ms-windows.misc, 1000 files found\n",
            "Processing comp.sys.ibm.pc.hardware, 1000 files found\n",
            "Processing comp.sys.mac.hardware, 1000 files found\n",
            "Processing comp.windows.x, 1000 files found\n",
            "Processing misc.forsale, 1000 files found\n",
            "Processing rec.autos, 1000 files found\n",
            "Processing rec.motorcycles, 1000 files found\n",
            "Processing rec.sport.baseball, 1000 files found\n",
            "Processing rec.sport.hockey, 1000 files found\n",
            "Processing sci.crypt, 1000 files found\n",
            "Processing sci.electronics, 1000 files found\n",
            "Processing sci.med, 1000 files found\n",
            "Processing sci.space, 1000 files found\n",
            "Processing soc.religion.christian, 997 files found\n",
            "Processing talk.politics.guns, 1000 files found\n",
            "Processing talk.politics.mideast, 1000 files found\n",
            "Processing talk.politics.misc, 1000 files found\n",
            "Processing talk.religion.misc, 1000 files found\n",
            "Classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
            "Number of samples: 19997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc4ZzA2C3LrI"
      },
      "source": [
        "# Shuffle the data\n",
        "seed = 1337\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(samples)\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(labels)\n",
        "\n",
        "# Extract a training & validation split\n",
        "validation_split = 0.2\n",
        "num_validation_samples = int(validation_split * len(samples))\n",
        "train_samples = samples[:-num_validation_samples]\n",
        "val_samples = samples[-num_validation_samples:]\n",
        "train_labels = labels[:-num_validation_samples]\n",
        "val_labels = labels[-num_validation_samples:]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXQalOY_3OAd"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
        "vectorizer.adapt(text_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2CaNsy83RzQ",
        "outputId": "b24cb4e7-4884-48cb-f6d0-fba4be402854"
      },
      "source": [
        "vectorizer.get_vocabulary()[:5]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'to', 'of']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38R61zzH3VIK",
        "outputId": "3e859ccf-3e06-4ae9-fa69-2d3c26b4d779"
      },
      "source": [
        "output = vectorizer([[\"the cat sat on the mat\"]])\n",
        "output.numpy()[0, :6]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2, 3355, 1684,   15,    2, 6327])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPJAMQjU3XO-"
      },
      "source": [
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BLE7s_f3Y2u",
        "outputId": "e40a070e-15d9-4672-9299-0f3f4a0aeaa0"
      },
      "source": [
        "test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
        "[word_index[w] for w in test]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3355, 1684, 15, 2, 6327]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B16e40Au3bqx",
        "outputId": "38bc50cd-fbb6-4c04-bf4b-1ff5ce638da4"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-18 10:30:45--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-05-18 10:30:45--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-05-18 10:30:46--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  4.81MB/s    in 2m 44s  \n",
            "\n",
            "2021-05-18 10:33:30 (5.03 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2IAGOp-3dqW",
        "outputId": "3d8b7159-1dea-4dd6-a95d-36b1bd98b870"
      },
      "source": [
        "path_to_glove_file = os.path.join(\n",
        "    os.path.expanduser(\"~\"), \"/content/glove.6B.100d.txt\"\n",
        ")\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59jCgpdr3geY",
        "outputId": "a2d30ab9-d9c8-4cb6-ee77-8528359b5494"
      },
      "source": [
        "num_tokens = len(voc) + 2\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted 17976 words (2024 misses)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJkol_6o33D0"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHZCEhNf34rB",
        "outputId": "34798b06-dfa9-466b-917f-367267c327d7"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded_sequences = embedding_layer(int_sequences_input)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
        "model = keras.Model(int_sequences_input, preds)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_5 (Embedding)      (None, None, 100)         2000200   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, None, 128)         64128     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, None, 128)         82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, None, 128)         82048     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 20)                2580      \n",
            "=================================================================\n",
            "Total params: 2,247,516\n",
            "Trainable params: 247,316\n",
            "Non-trainable params: 2,000,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cTDgK0i36wc"
      },
      "source": [
        "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
        "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
        "\n",
        "y_train = np.array(train_labels)\n",
        "y_val = np.array(val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgN74byp39sX"
      },
      "source": [
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"]\n",
        ")\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gxhIw0u4AEK"
      },
      "source": [
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = vectorizer(string_input)\n",
        "preds = model(x)\n",
        "end_to_end_model = keras.Model(string_input, preds)\n",
        "\n",
        "probabilities = end_to_end_model.predict(\n",
        "    [[\"this message is about computer graphics and 3D modeling\"]]\n",
        ")\n",
        "\n",
        "class_names[np.argmax(probabilities[0])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h_rPuupJNZo"
      },
      "source": [
        "Prueba 2 : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjeNW9N3JM6Y"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFSu0zOpJY42"
      },
      "source": [
        "#dowloading dataset\n",
        "data_path = keras.utils.get_file(\n",
        "    \"news20.tar.gz\",\n",
        "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n",
        "    untar=True,\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYAaeza9Je5N",
        "outputId": "88625bed-8c3b-42cb-b0b4-9650f45a6015"
      },
      "source": [
        "import pathlib\n",
        "#listado de directorios\n",
        "data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n",
        "dirnames = os.listdir(data_dir)\n",
        "print(\"Number of directories:\", len(dirnames))\n",
        "print(\"Directory names:\", dirnames)\n",
        "\n",
        "fnames = os.listdir(data_dir / \"comp.graphics\")\n",
        "print(\"Number of files in comp.graphics:\", len(fnames))\n",
        "print(\"Some example filenames:\", fnames[:5])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of directories: 20\n",
            "Directory names: ['rec.motorcycles', 'talk.politics.misc', 'soc.religion.christian', 'talk.religion.misc', 'sci.space', 'alt.atheism', 'comp.graphics', 'sci.crypt', 'rec.sport.hockey', 'sci.med', 'talk.politics.mideast', 'comp.os.ms-windows.misc', 'sci.electronics', 'comp.sys.ibm.pc.hardware', 'comp.windows.x', 'rec.autos', 'comp.sys.mac.hardware', 'misc.forsale', 'talk.politics.guns', 'rec.sport.baseball']\n",
            "Number of files in comp.graphics: 1000\n",
            "Some example filenames: ['38774', '39045', '38623', '37944', '38917']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IZFuT9CJmpu",
        "outputId": "d0dab21f-4b0c-4425-f20c-4ad81d9d690b"
      },
      "source": [
        "print(open(data_dir / \"comp.graphics\" / \"38500\").read())\n",
        "#ver el contenido de un texto "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!uunet!pipex!sunic!aun.uninett.no!nuug!nntp-oslo.uninett.no!kih.no!oved3b\n",
            "From: oved3b@kih.no (Ove Petter Tro)\n",
            "Newsgroups: comp.graphics\n",
            "Subject: Re: need a viewer for gl files\n",
            "Date: 20 Apr 1993 11:49:32 GMT\n",
            "Organization: Kongsberg College of Engineering\n",
            "Lines: 16\n",
            "Distribution: world\n",
            "Message-ID: <1r0o0c$l5u@ratatosk.uninett.no>\n",
            "References: <1qu36i$kh7@dux.dundee.ac.uk>\n",
            "NNTP-Posting-Host: knoll.kih.no\n",
            "\n",
            "In article <1qu36i$kh7@dux.dundee.ac.uk>, dwestner@cardhu.mcs.dundee.ac.uk (Dominik Westner) writes:\n",
            "|> the subject says it all. Is there a PD viewer for gl files (for X)?\n",
            "\n",
            "Try xviewgl.\n",
            "(filename xviewgl_v1.1.tar.Z on lots of bases)\n",
            "\n",
            "- Ove\n",
            "-- \n",
            "- ----------==========###########==========-------- -\n",
            "    //                     | \"What do you think\n",
            "  \\X/ (Yep, me too...)     |  this is?  Real life?\"\n",
            "Ove Petter Tro,            |    - Ford Fairlane.\n",
            "Kongsberg College          |\n",
            "of Engineering, Norway     | email: ovep@kih.no\n",
            "- ----------==========###########==========-------- -\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mnf3VkbPJ3G4",
        "outputId": "0c96fc91-e48d-40ba-c767-adc909292198"
      },
      "source": [
        "#Eliminacion de las cabeceras\n",
        "samples = []\n",
        "labels = []\n",
        "class_names = []\n",
        "class_index = 0\n",
        "for dirname in sorted(os.listdir(data_dir)):\n",
        "    class_names.append(dirname)\n",
        "    dirpath = data_dir / dirname\n",
        "    fnames = os.listdir(dirpath)\n",
        "    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n",
        "    for fname in fnames:\n",
        "        fpath = dirpath / fname\n",
        "        f = open(fpath, encoding=\"latin-1\")\n",
        "        content = f.read()\n",
        "        lines = content.split(\"\\n\")\n",
        "        lines = lines[10:]\n",
        "        content = \"\\n\".join(lines)\n",
        "        samples.append(content)\n",
        "        labels.append(class_index)\n",
        "    class_index += 1\n",
        "\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"Number of samples:\", len(samples))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing alt.atheism, 1000 files found\n",
            "Processing comp.graphics, 1000 files found\n",
            "Processing comp.os.ms-windows.misc, 1000 files found\n",
            "Processing comp.sys.ibm.pc.hardware, 1000 files found\n",
            "Processing comp.sys.mac.hardware, 1000 files found\n",
            "Processing comp.windows.x, 1000 files found\n",
            "Processing misc.forsale, 1000 files found\n",
            "Processing rec.autos, 1000 files found\n",
            "Processing rec.motorcycles, 1000 files found\n",
            "Processing rec.sport.baseball, 1000 files found\n",
            "Processing rec.sport.hockey, 1000 files found\n",
            "Processing sci.crypt, 1000 files found\n",
            "Processing sci.electronics, 1000 files found\n",
            "Processing sci.med, 1000 files found\n",
            "Processing sci.space, 1000 files found\n",
            "Processing soc.religion.christian, 997 files found\n",
            "Processing talk.politics.guns, 1000 files found\n",
            "Processing talk.politics.mideast, 1000 files found\n",
            "Processing talk.politics.misc, 1000 files found\n",
            "Processing talk.religion.misc, 1000 files found\n",
            "Classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
            "Number of samples: 19997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebD51nCcKAm1"
      },
      "source": [
        "#Division del dataset entre el conjunto de validacion entrenamiento y test\n",
        "# Shuffle the data\n",
        "seed = 1337\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(samples)\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(labels)\n",
        "\n",
        "# Extract a training & validation split\n",
        "validation_split = 0.2\n",
        "num_validation_samples = int(validation_split * len(samples))\n",
        "train_samples = samples[:-num_validation_samples]\n",
        "val_samples = samples[-num_validation_samples:]\n",
        "train_labels = labels[:-num_validation_samples]\n",
        "val_labels = labels[-num_validation_samples:]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE0tTHyIKJEN"
      },
      "source": [
        "#Creamos un vocabulario de 20000 palabras\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
        "vectorizer.adapt(text_ds)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sDg-f2-Kkf1",
        "outputId": "e2f951f9-c847-4c69-f754-d8306e2b7f85"
      },
      "source": [
        "#Mostramos 10 primeras palabras del vocabulario\n",
        "vocabulario=vectorizer.get_vocabulary()[1:10]\n",
        "#Estas palabras son convertidas en enteros\n",
        "\n",
        "for el in vocabulario:\n",
        "  print(el)\n",
        "  output = vectorizer([[el]])\n",
        "  print('representación numérica'+str(output))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[UNK]\n",
            "representación numéricatf.Tensor(\n",
            "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]], shape=(1, 200), dtype=int64)\n",
            "the\n",
            "representación numéricatf.Tensor(\n",
            "[[2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]], shape=(1, 200), dtype=int64)\n",
            "to\n",
            "representación numéricatf.Tensor(\n",
            "[[3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]], shape=(1, 200), dtype=int64)\n",
            "of\n",
            "representación numéricatf.Tensor(\n",
            "[[4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]], shape=(1, 200), dtype=int64)\n",
            "a\n",
            "representación numéricatf.Tensor(\n",
            "[[5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]], shape=(1, 200), dtype=int64)\n",
            "and\n",
            "representación numéricatf.Tensor(\n",
            "[[6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]], shape=(1, 200), dtype=int64)\n",
            "in\n",
            "representación numéricatf.Tensor(\n",
            "[[7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]], shape=(1, 200), dtype=int64)\n",
            "is\n",
            "representación numéricatf.Tensor(\n",
            "[[8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]], shape=(1, 200), dtype=int64)\n",
            "i\n",
            "representación numéricatf.Tensor(\n",
            "[[9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]], shape=(1, 200), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCJ5DUOALUbE",
        "outputId": "0b4d9506-a309-4eb1-9b43-fb734f652dae"
      },
      "source": [
        "# Mapeamos las palabras a un diccionario\n",
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))\n",
        "test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
        "[word_index[w] for w in test]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3692, 1826, 15, 2, 6103]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFi5SRJSLfRB"
      },
      "source": [
        "#Cargamos embeddings hechos\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CunMOBGL_AU",
        "outputId": "73074f42-0dbb-4f9c-d523-9bab0f4ac4bb"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-20 19:10:46--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-05-20 19:10:46--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-05-20 19:10:47--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  4.99MB/s    in 2m 41s  \n",
            "\n",
            "2021-05-20 19:13:28 (5.12 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
            "\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8LtgVVUMGfV",
        "outputId": "4d702556-a7a3-4031-f9a1-0d37bf91b37e"
      },
      "source": [
        "#descarga del dataset de pruebas\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(\"glove.6B.100d.txt\") as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h76m09PGMYQk",
        "outputId": "8372aa97-3096-4e19-c740-87601a228b3e"
      },
      "source": [
        "#Se crea la matriz de embeddings con las palabras del archivo leido\n",
        "num_tokens = len(voc) + 2\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted 17959 words (2041 misses)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkTl5rjrNS0u",
        "outputId": "47696520-441c-49f3-de18-cd4ece5f3b51"
      },
      "source": [
        "#Construcción del modelo\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded_sequences = embedding_layer(int_sequences_input)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
        "model = keras.Model(int_sequences_input, preds)\n",
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, None, 100)         2000200   \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, None, 128)         64128     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, None, 128)         82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, None, 128)         82048     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 20)                2580      \n",
            "=================================================================\n",
            "Total params: 2,247,516\n",
            "Trainable params: 247,316\n",
            "Non-trainable params: 2,000,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC6DOvRWNdND"
      },
      "source": [
        "#Entrenamiento del modelo\n",
        "x_train = vectorizer(np.array([[s] for s in train_samples[0:1000]])).numpy()\n",
        "x_val = vectorizer(np.array([[s] for s in val_samples[0:1000]])).numpy()\n",
        "\n",
        "y_train = np.array(train_labels[0:1000])\n",
        "y_val = np.array(val_labels[0:1000])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAfLqW8PNf6x",
        "outputId": "885b8f29-94db-4a6f-adc4-0272bed98a13"
      },
      "source": [
        "#Compilación del modelo\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"]\n",
        ")\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 28s 59ms/step - loss: 3.1227 - acc: 0.0546 - val_loss: 2.9929 - val_acc: 0.0710\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.9786 - acc: 0.0760 - val_loss: 2.9704 - val_acc: 0.0970\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.9342 - acc: 0.1078 - val_loss: 2.9069 - val_acc: 0.1240\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.8438 - acc: 0.1381 - val_loss: 2.9485 - val_acc: 0.0740\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.8479 - acc: 0.1198 - val_loss: 2.8368 - val_acc: 0.1110\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.6942 - acc: 0.1510 - val_loss: 2.6569 - val_acc: 0.1810\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 2.5459 - acc: 0.2039 - val_loss: 2.5014 - val_acc: 0.1710\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.4599 - acc: 0.1964 - val_loss: 2.5158 - val_acc: 0.1530\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.3163 - acc: 0.2628 - val_loss: 2.3367 - val_acc: 0.2190\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.2517 - acc: 0.2648 - val_loss: 2.4099 - val_acc: 0.1850\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.2130 - acc: 0.2961 - val_loss: 2.2605 - val_acc: 0.2500\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.0514 - acc: 0.3286 - val_loss: 2.2451 - val_acc: 0.2420\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.0202 - acc: 0.3502 - val_loss: 2.1817 - val_acc: 0.2540\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.8758 - acc: 0.4185 - val_loss: 2.1810 - val_acc: 0.2330\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 1.8375 - acc: 0.4143 - val_loss: 2.2916 - val_acc: 0.2500\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 1.8292 - acc: 0.4166 - val_loss: 2.2787 - val_acc: 0.2620\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 1.7435 - acc: 0.4430 - val_loss: 2.1764 - val_acc: 0.2930\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 1.6692 - acc: 0.4758 - val_loss: 1.9550 - val_acc: 0.3220\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 1.4992 - acc: 0.5207 - val_loss: 2.1026 - val_acc: 0.3070\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1.4934 - acc: 0.5097 - val_loss: 2.0138 - val_acc: 0.3280\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f527069b910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "sHj7eR1RNtwz",
        "outputId": "68371d96-056b-4a48-8d7b-b0be501a91aa"
      },
      "source": [
        "#Finalmente exportamos el modelo\n",
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = vectorizer(string_input)\n",
        "preds = model(x)\n",
        "end_to_end_model = keras.Model(string_input, preds)\n",
        "\n",
        "probabilities = end_to_end_model.predict(\n",
        "    [[\"Biden signs bill aimed at addressing rise in anti-Asian hate crimes\"],[\"Hello how you are doing\"]]\n",
        ")\n",
        "\n",
        "class_names[np.argmax(probabilities[1])]\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5202075830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'comp.graphics'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hd_0BCHSlSy"
      },
      "source": [
        "Recuerda guardar tus cambios en tu repositorio de GitHub usando la opción \"Save in GitHub\" del menú File."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMGWXN-wJlzC"
      },
      "source": [
        ""
      ]
    }
  ]
}